{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and Data Journalism\n",
    "## HODP Bootcamp Week 4\n",
    "### March 6, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals for this week:\n",
    "* Learn what a significance test and confidence interval are\n",
    "* Practice basic linear regression\n",
    "* Understand the difference between correlation and causation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters vs. Statistics\n",
    "* In data journalism, we're often interested in estimating *pararameters* of interest, which are fixed but unknown quantities\n",
    "* We estimate these with *sample statistics*, which are known but random quantities\n",
    "* Seems very simple but mixing up the two is a common pitfall in journalism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data\n",
    "Here is a real dataset from HODP that you're probably familiar with: our House rankings data. You've worked with this in a previous bootcamp, so the data should be fairly familiar to you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adams</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabot</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "      <td>118</td>\n",
       "      <td>148</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kirkland</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mather</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>67</td>\n",
       "      <td>112</td>\n",
       "      <td>37</td>\n",
       "      <td>55</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quincy</th>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>90</td>\n",
       "      <td>71</td>\n",
       "      <td>82</td>\n",
       "      <td>65</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leverett</th>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "      <td>94</td>\n",
       "      <td>66</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dunster</th>\n",
       "      <td>45</td>\n",
       "      <td>67</td>\n",
       "      <td>113</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Currier</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>92</td>\n",
       "      <td>114</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eliot</th>\n",
       "      <td>37</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>76</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lowell</th>\n",
       "      <td>152</td>\n",
       "      <td>106</td>\n",
       "      <td>63</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pforzheimer</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>66</td>\n",
       "      <td>158</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winthrop</th>\n",
       "      <td>176</td>\n",
       "      <td>146</td>\n",
       "      <td>78</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1    2    3   4   5   6   7   8    9   10   11   12\n",
       "House                                                             \n",
       "Adams         20   15   24  38  37  44  67  75   74   28   32   80\n",
       "Cabot          5   13   16  17   7  20  16  31   49  118  148   94\n",
       "Kirkland      19   19   35  50  71  63  72  70   56   24   24   31\n",
       "Mather        17   15   19  25  27  40  44  67  112   37   55   76\n",
       "Quincy        28   43   55  90  71  82  65  44   21   17   14    4\n",
       "Leverett      11   22   40  73  76  81  94  66   36   18   11    6\n",
       "Dunster       45   67  113  56  70  42  44  52   19   10   11    5\n",
       "Currier       14   10   16  15  18  19  20  23   43   92  114  150\n",
       "Eliot         37   57   60  67  57  76  49  40   38   23   16   14\n",
       "Lowell       152  106   63  51  45  35  22  24   14    5    7   10\n",
       "Pforzheimer   10   21   15   6  16  19  29  33   66  158   98   63\n",
       "Winthrop     176  146   78  46  39  13  12   9    6    4    4    1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rankings = pd.read_csv(\"house_rankings_2018.csv\")\n",
    "rankings.set_index(\"House\", inplace = True)\n",
    "rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Tests and P-Values\n",
    "### Do people prefer Adams or Cabot?\n",
    "We're going to conduct a two sample t-test. We can do this with SciPy's built in t-test function. A one sample t-test is a test of how \"far\" a sample statistic is from a hypothesized \"true\" value. For example, if I claim that 50% of Harvard students are left handed, we might do a one sample t-test to see if survey data can disprove my claim. A two sample t-test is a test of how \"far\" two sample statistics are from each other; we're usually trying to see if they are significantly different from each other. Let's use Python to see if the mean ratings for Adams and Cabot are significantly different. Note that you may need to reshape the data a little bit; we want one data point for each ranking. In other words, you want to \"expand\" Cabot's 5 \\#1 ratings to be 1, 1, 1, 1, 1, and do the same for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adams = []\n",
    "cabot = []\n",
    "\n",
    "for i in range(0, 12):\n",
    "    for val in np.repeat(i, rankings.values[0, i]):\n",
    "        adams.append(val + 1)\n",
    "    for val in np.repeat(i, rankings.values[1, i]):\n",
    "        cabot.append(val + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned up the data into the format we want, we can pretty simply conduct a t-test. We're testing the null hypothesis that the two houses have the same true average ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-10.553882150189777, pvalue=8.152088510595662e-25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.ttest_ind(adams, cabot, equal_var = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Results\n",
    "Now, we have a p-value. The p-value is often misunderstood or improperly interpreted, so it's very important to know what it actually means. **A p-value is the probability of observing our data, given that the null hypothesis is correct.** So, we assume that our data are random, but the true values are fixed. A common pitfall when interpreting p-values is to think of the p-value as the probability of the null hypothesis being correct, but this interpretation is wrong. Looking at the results above with this in mind, we can see that if Adams and Cabot truly had the same average ranking, there would be an astronomically low probability of getting the data we got (though still possible), so we can pretty reasonably reject the null hypothesis and say that the two houses do not have equal rankings. Because the test statistic is negative, we can see that Adams has a lower (better) ranking. \n",
    "\n",
    "In general, a common rule of thumb is to reject the null hypothesis when the p-value is less than 0.05. When we fail to reject the null hypothesis, we should never say that we \"accept\" or \"prove\" the null. All we have done is failed to reject it; we can never prove the null hypothesis true.\n",
    "\n",
    "**Now, try finding the significance of the difference between two other houses, and interpret your results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the significance here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret your results here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about other parameters?\n",
    "\n",
    "We can also do a ton of other types of comparisons. For example, we can look at proportions and not just sample means, and in a regression, we can examine the significance of the coefficients in the model. We can also do one-sample tests, where we compare our statistic to a set value. For example, if Dean Khurana tells you that he believes 75% of students support the social group sanctions, but your HODP survey suggests that only 65% of students support the sanctions, you can test whether that difference is sufficiently large to dispute Khurana's claim. \n",
    "\n",
    "**With the house ranking data from before, formulate another question that involves a test other than a two-sample test of difference in means, and try to answer it below using the data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the data to answer your question here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equally important in data journalism: add an interpretation of your data analysis here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "You're probably quite familiar with point estimates in Statistics, where we say the mean ranking for Cabot is, say, 9.5. A confidence interval is, as the name suggests, an interval that we think the true value is likely to fall in. These intervals have a certain level of *confidence*, or the percentage of intervals calculated using this method that contain the true value. There is a trade off between confidence and width - higher confidence is great, but it will also widen the interval, which can make it less useful. For example, you can construct a 100% confidence interval for anything, but it goes from negative infinity to positive infinity, and tells us nothing about the parameter of interest.\n",
    "\n",
    "In practice, 95% confidence intervals are quite popular, which means that, on average, 19 out of every 20 contain the true value of the parameter of interest. A common pitfall with confidence intervals is to say there is a 95% chance that the true value falls inside the interval, but this interpretation is incorrect, so please stay away from this phrase in your articles.\n",
    "\n",
    "Now, let's construct a 95% confidence interval for the average ranking for Adams house. We have to do a bit more work to generate a confidence interval in Python. We need to provide SciPy's interval function with a confidence level, a center (the sample mean), and a scale (the standard error, which is the sample standard deviation divided by the square root of one less than the length of the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.325386121402705, 7.843153204439991)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, sigma = np.mean(adams), np.std(adams)\n",
    "\n",
    "conf_int = stats.norm.interval(0.95, \n",
    "                               loc = mean, \n",
    "                               scale = sigma/np.sqrt(len(adams) - 1))\n",
    "conf_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try generating an interval for the Cabot data using a different confidence level, and interpret your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the interval here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret your results here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causation vs. Correlation\n",
    "You've all probably heard this before, but it's important to hear it again: correlation does not imply causation. It's pretty rare that we'll be able to show causation in a HODP article, so it's important to frame most of our work as a correlation or trend we noticed, rather than as a direct cause. Often, though, it will intuitively make sense that there \"should\" or at least \"could\" be a causal connection. In those cases, make sure to frame your writing as a \"possible explanation\" than as a statement of what is going on. For example, the percentage of female concentrators by department is likely strongly correlated with the percentage of female faculty members, and there is probably some causal effect here. However, it's best to cite other research on whether such a trend has a causal effect, or to cite relevant quantitative work. For example, in an article about gender balance in different departments, we could talk about existing research on the effect of faculty gender on students and potentially cite relevant Crimson articles, but we should not conclude that (for example) low female faculty presence in Mathematics *causes* low female student presence in Mathematics.\n",
    "\n",
    "For people who are particularly interested in causation, talk to Stephen or look at Stat 111 (Statistical Inference), Stat 186 (Causal Inference), and Ec 1123 (Econometrics).\n",
    "\n",
    "Let's look at some examples of how we might be able to find correlations that are likely not causal. This will also show you how to find a correlation coefficient. If all you want is the correlation, it's very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7635806435842531, 0.0038495884100404063)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "#monthly high temps in Boston\n",
    "bostontemps = [37, 39, 46, 57, 67, 77, 82, 81, 73, 62, 52, 42]\n",
    "levCounts = list(rankings.values[5,])\n",
    "pearsonr(levCounts, bostontemps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Regression\n",
    "Regression is a very useful tool for prediction. Linear regressions allow us to easily model a linear relationship between a response/dependent/Y variable and 1 or more predictor/independent/X variables. This is a very widely used technique, so if you plan to use regression in your project, please come talk to us for a more in depth treatment of the subject, but here are the basics! Regressions in Python are fairly easy to do: we just need a Y list, and at least one X list of equal length! Below, we've built a regression based on the same Leverett and temperature data from above. Note that you may sometimes need to reshape data a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-42.96885688068292, array([1.46800879])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression()\n",
    "bostontemps = np.array(bostontemps).reshape(-1, 1)\n",
    "\n",
    "#X, Y is the order\n",
    "reg = lm.fit(bostontemps, levCounts)\n",
    "[reg.intercept_, reg.coef_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more useful model\n",
    "The model above is probably not very useful. On your own, try fitting a model to predict number of first-choice votes each house received, with at least two predictor variables. I've given you two possible variables below, though you're welcome to find more, or different ones. Again, note that you may need to reshape data.\n",
    "\n",
    "*Hint: You still need to find the dependent variable, and structure it like the `levCounts` variable above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b208ed99100f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrenovated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenovated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#find the response variable and format it properly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#walking time from Widener Library (in minutes), from Google Maps\n",
    "dist = [2, 15, 7, 8, 3, 5, 7, 16, 7, 2, 17, 6]\n",
    "#was the house renovated in last 10 years? 1 if true\n",
    "renovated = [0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1]\n",
    "\n",
    "X = np.matrix([dist, renovated]).transpose()\n",
    "\n",
    "#find the response variable and format it properly\n",
    "#fit the model\n",
    "#print out the coefficients and intercept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Finally, one of the most useful things we can do with a predictive model is make predictions! Assuming you called your model `reg`, use the command below to predict the number of first choice votes for Adams House after the renovations begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86.05683956]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(np.array([[2, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
